import re
from typing import List, Optional
from urllib.parse import urlparse

# OpenAI ì‚¬ìš©ì€ ì„ íƒ(ì—†ì–´ë„ ë™ì‘)
try:
    from openai import OpenAI
except Exception:
    OpenAI = None

# ë³¸ë¬¸ í™•ì¸(ì¡°ê±´ë¶€)ìš©
import requests
from bs4 import BeautifulSoup


# =========================
# OpenAI client
# =========================
def _get_client():
    import os
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or OpenAI is None:
        return None
    return OpenAI(api_key=api_key)


# =========================
# Helpers
# =========================
_SENT_SPLIT_RE = re.compile(r"(?<=[.!?])\s+|(?<=[ã€‚ï¼ï¼Ÿ])\s+")


def _is_en(language: str) -> bool:
    return (language or "ko").strip().lower().startswith("en")


def _norm_text(s: str) -> str:
    s = re.sub(r"\s+", " ", (s or "")).strip()
    s = re.sub(r"[\"'â€œâ€â€˜â€™]", "", s)
    return s


def _is_image_file_url(url: str) -> bool:
    try:
        path = urlparse(url or "").path.lower()
    except Exception:
        path = (url or "").lower()
    return path.endswith((".jpg", ".jpeg", ".png", ".gif", ".webp"))


def _is_meaningless_summary(summary: str) -> bool:
    """
    summaryê°€ ì‚¬ì‹¤ìƒ 'ë‚´ìš© ì—†ìŒ'ì— ê°€ê¹Œìš´ ë¬¸êµ¬ì¸ì§€ íŒë³„(ë³´ìˆ˜ì ).
    """
    s = _norm_text(summary).lower()
    if not s:
        return True

    meaningless_patterns = [
        "ìì„¸í•œ ë‚´ìš©", "ìì„¸íˆ ë³´ê¸°", "ìì„¸íˆë³´ê¸°",
        "ê¸°ì‚¬ ë³´ê¸°", "ê¸°ì‚¬ë³´ê¸°", "ì›ë¬¸ ë³´ê¸°", "ì›ë¬¸ë³´ê¸°",
        "ë”ë³´ê¸°", "ë³´ê¸°", "ë°”ë¡œê°€ê¸°",
        "ì‚¬ì§„", "ì´ë¯¸ì§€", "ì˜ìƒ", "ë™ì˜ìƒ",
        "ê´€ë ¨ ê¸°ì‚¬", "ê´€ë ¨ê¸°ì‚¬",
        "í´ë¦­", "í™•ì¸",
    ]
    return any(p in s for p in meaningless_patterns)


def _is_summary_same_as_title(title: str, summary: str) -> bool:
    t = _norm_text(title).lower()
    s = _norm_text(summary).lower()
    if not t or not s:
        return False
    return t == s or t in s or s in t


def _fetch_html(url: str, timeout: int = 10) -> Optional[str]:
    if not url:
        return None
    try:
        r = requests.get(url, timeout=timeout, headers={"User-Agent": "Mozilla/5.0"})
        if r.status_code != 200:
            return None
        return r.text
    except Exception:
        return None


def _extract_text_and_imgcount(html: str) -> (str, int):
    soup = BeautifulSoup(html or "", "html.parser")
    for tag in soup(["script", "style", "noscript"]):
        tag.decompose()

    text = soup.get_text(separator=" ", strip=True)
    text = re.sub(r"\s+", " ", text).strip()
    img_count = len(soup.find_all("img"))
    return text, img_count


def _is_image_only_ad_page(body_text: str, img_count: int) -> bool:
    body = _norm_text(body_text)
    return len(body) < 40 and img_count >= 1


def _enforce_sentence_and_length(text: str, max_sentences: int, max_chars: int) -> str:
    """
    - ëª¨ë¸ì´ ê¸¸ê²Œ ì“°ê±°ë‚˜ ë¬¸ì¥ ìˆ˜ê°€ ëŠ˜ì–´ë‚˜ëŠ” ê²½ìš°ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ìµœì¢… ì•ˆì „ë§.
    - 1~3ë¬¸ì¥ ë²”ìœ„ë¡œë§Œ ì˜ë¼ì„œ ë°˜í™˜ (ê°€ëŠ¥í•œ í•œ ì›ë¬¸ ë³´ì¡´).
    """
    s = _norm_text(text)
    if not s:
        return s

    parts = [p.strip() for p in _SENT_SPLIT_RE.split(s) if p.strip()]
    if parts:
        s = " ".join(parts[:max_sentences]).strip()

    if len(s) > max_chars:
        s = s[:max_chars].rstrip() + "â€¦"
    return s


def _auto_sentence_target(n_items: int) -> int:
    # ê¸°ì¡´ ì •ì±…: 2~3ë¬¸ì¥ (ê¸°ì‚¬ ìˆ˜ê°€ ëŠ˜ì–´ë„ 3ë¬¸ì¥ ìœ ì§€)
    if n_items <= 3:
        return 2
    return 3


# =========================
# Prompts (KO/EN)
# =========================
def _prompt_title_only(title: str, language: str) -> str:
    if _is_en(language):
        return f"""
You are writing a factual daily newsletter summary for executives in the contact lens / optical industry.

ABSOLUTE RULES (MOST IMPORTANT):
- Use ONLY what is explicitly stated in the Title.
- Do NOT add any facts, numbers, entities, brands, causes, outcomes, or interpretations not present.
- No exaggeration, no speculation, no forecasting.
- Keep proper nouns as-is (Korean names/brands are allowed as proper nouns).
- Output MUST be in English.
- Output 2â€“3 short sentences.

[Title]
{title}

[Output]
""".strip()

    return f"""
ë„ˆëŠ” ì½˜íƒíŠ¸ë Œì¦ˆ/ì•ˆê²½ ì—…ê³„ ë°ì¼ë¦¬ ë‰´ìŠ¤ë ˆí„°ë¥¼ ì„ì›ì—ê²Œ ë³´ê³ í•˜ëŠ” ë¹„ì„œë‹¤.
ì•„ë˜ [ì œëª©]ë§Œì„ ê·¼ê±°ë¡œ 2~3ë¬¸ì¥ ìš”ì•½ì„ ì‘ì„±í•˜ë¼.

ğŸš« ì ˆëŒ€ ê·œì¹™:
- ì œëª©ì— ì—†ëŠ” ì‚¬ì‹¤/ìˆ«ì/ì£¼ì²´/ë¸Œëœë“œ/ì›ì¸/ê²°ê³¼ ì ˆëŒ€ ì¶”ê°€ ê¸ˆì§€
- ê³¼ì¥/ì¶”ì¸¡/ì „ë§/í‰ê°€ ê¸ˆì§€
- 'ì¶œì‹œ'ë¼ëŠ” ë‹¨ì–´ê°€ ì œëª©ì— ëª…í™•íˆ ìˆëŠ” ê²½ìš°ë§Œ ì‚¬ìš©
- 2~3ë¬¸ì¥

[ì œëª©]
{title}

[ì¶œë ¥]
""".strip()


def _prompt_compress_long_summary(title: str, summary: str, language: str) -> str:
    if _is_en(language):
        return f"""
You are writing a factual daily newsletter summary for executives in the contact lens / optical industry.

ABSOLUTE RULES (MOST IMPORTANT):
- Use ONLY what is explicitly stated in the Input Summary.
- Do NOT add any facts, numbers, entities, brands, causes, outcomes, or interpretations not present.
- No exaggeration, no speculation, no forecasting.
- Keep proper nouns as-is (Korean names/brands are allowed as proper nouns).
- Output MUST be in English.
- Output 2â€“3 short sentences.

[Title]
{title}

[Input Summary]
{summary}

[Output]
""".strip()

    return f"""
ë„ˆëŠ” ì½˜íƒíŠ¸ë Œì¦ˆ/ì•ˆê²½ ì—…ê³„ ë°ì¼ë¦¬ ë‰´ìŠ¤ë ˆí„°ë¥¼ ì„ì›ì—ê²Œ ë³´ê³ í•˜ëŠ” ë¹„ì„œë‹¤.
ì•„ë˜ [ì œëª©/ìš”ì•½]ì„ ê·¼ê±°ë¡œ 'ê¸´ ìš”ì•½ì„ 2~3ë¬¸ì¥ìœ¼ë¡œ ì••ì¶•'í•˜ë¼.

ğŸš« ì ˆëŒ€ ê·œì¹™:
- ì…ë ¥ì— ì—†ëŠ” ì‚¬ì‹¤/ìˆ«ì/ì£¼ì²´/ë¸Œëœë“œ/ì›ì¸/ê²°ê³¼ ì ˆëŒ€ ì¶”ê°€ ê¸ˆì§€
- ê³¼ì¥/ì¶”ì¸¡/ì „ë§/í‰ê°€ ê¸ˆì§€
- 'ì¶œì‹œ ì˜ˆì •'ì¸ ê²½ìš°ë§Œ 'ì¶œì‹œ'ë¼ëŠ” ë‹¨ì–´ ì‚¬ìš©
- 2~3ë¬¸ì¥

[ì œëª©]
{title}

[ìš”ì•½]
{summary}

[ì¶œë ¥]
""".strip()


def _prompt_summarize_from_body(title: str, body_text: str, language: str) -> str:
    if _is_en(language):
        return f"""
You are writing a factual daily newsletter summary for executives in the contact lens / optical industry.

ABSOLUTE RULES (MOST IMPORTANT):
- Use ONLY what is explicitly stated in the Article Body.
- Do NOT add any facts, numbers, entities, brands, causes, outcomes, or interpretations not present.
- No exaggeration, no speculation, no forecasting.
- Keep proper nouns as-is (Korean names/brands are allowed as proper nouns).
- Output MUST be in English.
- Output 2â€“3 short sentences.

[Title]
{title}

[Article Body]
{body_text}

[Output]
""".strip()

    return f"""
ë„ˆëŠ” ì½˜íƒíŠ¸ë Œì¦ˆ/ì•ˆê²½ ì—…ê³„ ë°ì¼ë¦¬ ë‰´ìŠ¤ë ˆí„°ë¥¼ ì„ì›ì—ê²Œ ë³´ê³ í•˜ëŠ” ë¹„ì„œë‹¤.
ì•„ë˜ [ê¸°ì‚¬ ë³¸ë¬¸]ë§Œì„ ê·¼ê±°ë¡œ 2~3ë¬¸ì¥ ìš”ì•½ì„ ì‘ì„±í•˜ë¼.

ğŸš« ì ˆëŒ€ ê·œì¹™:
- ê¸°ì‚¬ì— ì—†ëŠ” ì‚¬ì‹¤/ìˆ«ì/ì£¼ì²´/ë¸Œëœë“œ/ì›ì¸/ê²°ê³¼ë¥¼ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ ê²ƒ
- ê³¼ì¥/ì¶”ì¸¡/ì „ë§/í‰ê°€ ê¸ˆì§€
- 'ì¶œì‹œ ì˜ˆì •'ì¸ ê²½ìš°ë§Œ 'ì¶œì‹œ'ë¼ëŠ” ë‹¨ì–´ ì‚¬ìš©
- ì•ˆê²½í…Œ/ë Œì¦ˆ/ì œí’ˆì˜ ë¸Œëœë“œëª…ì€ ë³¸ë¬¸ì— ëª…í™•íˆ ì–¸ê¸‰ëœ ê²½ìš°ì—ë§Œ ì‚¬ìš©
- ë¸Œëœë“œê°€ ë¶ˆëª…í™•í•˜ë©´ íŠ¹ì • ì£¼ì²´ë¥¼ ë‹¨ì •í•˜ì§€ ë§ ê²ƒ
- 2~3ë¬¸ì¥

[ì œëª©]
{title}

[ê¸°ì‚¬ ë³¸ë¬¸]
{body_text}

[ì¶œë ¥]
""".strip()


def _call_openai(client, prompt: str, temperature: float = 0.2) -> str:
    r = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=temperature,
    )
    return (r.choices[0].message.content or "").strip()


def _ensure_min_chars_english(summary: str, title: str, min_chars: int, max_chars: int, client) -> str:
    """
    ì˜ì–´ ìš”ì•½ì´ ë„ˆë¬´ ì§§ì•„ should_exclude_article()ì˜ 'ìš”ì•½ ì§§ìŒ' í•„í„°(<40)ì— ê±¸ë¦¬ëŠ” ë¬¸ì œ ë°©ì§€ìš©.
    âœ… íŒ©íŠ¸ ì¶”ê°€ ì—†ì´ 'ê°™ì€ ì˜ë¯¸ë¥¼ ë” í’€ì–´ì„œ' ì“°ë„ë¡ ì¬ì‘ì„±í•œë‹¤.
    """
    s = _norm_text(summary)
    if len(s) >= min_chars:
        return s

    # 1) AIë¡œ ë™ì¼ ì˜ë¯¸ í™•ì¥
    if client is not None:
        try:
            prompt = f"""Rewrite the following summary in English.
Rules:
- Keep EXACTLY the same meaning; do NOT add any new facts.
- Keep it 2â€“3 sentences.
- Make it at least {min_chars} characters but not more than {max_chars} characters.
- Keep proper nouns as-is (Korean names/brands are allowed as proper nouns).
Input:
Title: {title}
Summary: {s}
Output:"""
            s2 = _call_openai(client, prompt, temperature=0.2)
            s2 = _enforce_sentence_and_length(s2, max_sentences=3, max_chars=max_chars)
            if len(_norm_text(s2)) >= min_chars:
                return _norm_text(s2)
        except Exception:
            pass

    # 2) ìµœí›„ ìˆ˜ë‹¨: ì œëª©ì„ ê´„í˜¸ë¡œ ë§ë¶™ì—¬ ê¸¸ì´ í™•ë³´ (íŒ©íŠ¸ ì¶”ê°€ ì—†ìŒ)
    if title:
        suffix = f" (Title: {title})"
        out = (s + suffix).strip()
        if len(out) > max_chars:
            out = out[:max_chars].rstrip() + "â€¦"
        return out

    return s


def _fallback_overall(language: str = "ko") -> str:
    if _is_en(language):
        return "A briefing could not be generated due to missing AI access; please refer to the article list below."
    return "AI ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ì–´ ê¸°ì‚¬ ëª©ë¡ë§Œ ê³µìœ ë“œë¦½ë‹ˆë‹¤."


# =========================
# A. ê¸°ì‚¬ë³„ summary ì •ì œ/ìƒì„±
# =========================
def refine_article_summaries(articles: List, language: str = "ko") -> None:
    """
    âœ… ê° ê¸°ì‚¬ summary ì •ì±…(í•µì‹¬ ë¡œì§ ìœ ì§€)
    - ì˜ì–´ ëª¨ë“œì—ì„œ ìš”ì•½ì´ ë„ˆë¬´ ì§§ì•„ ê¸°ì‚¬ ìì²´ê°€ ì œì™¸ë˜ëŠ” ë¬¸ì œë¥¼ ë§‰ê¸° ìœ„í•´
      (íŒ©íŠ¸ ì¶”ê°€ ì—†ì´) 'ê°™ì€ ì˜ë¯¸ë¡œ ë” í’€ì–´ì“°ëŠ”' ìµœì†Œ ê¸¸ì´ ë³´ì •ë§Œ ì¶”ê°€.
    """
    client = _get_client()

    if _is_en(language):
        LONG_SUMMARY_THRESHOLD = 260
        MAX_SUMMARY_CHARS = 220
        MIN_SUMMARY_CHARS = 60
    else:
        LONG_SUMMARY_THRESHOLD = 150
        MAX_SUMMARY_CHARS = 105
        MIN_SUMMARY_CHARS = 0

    for a in articles:
        title = _norm_text(getattr(a, "title", "") or "")
        summary_raw = getattr(a, "summary", "") or ""
        summary = _norm_text(summary_raw)
        link = (getattr(a, "link", "") or "").strip()

        # âœ… ë„¤ì´ë²„(OpenAPI í¬í•¨) íŒë³„ í”Œë˜ê·¸
        is_naver = bool(getattr(a, "is_naver", False))

        # ë§í¬ê°€ ì´ë¯¸ì§€ íŒŒì¼ì´ë©´: ê´‘ê³ /ë°°ë„ˆë¡œ ë³´ê³  summaryëŠ” ë¹ˆê°’
        if _is_image_file_url(link):
            a.summary = ""
            continue

        # 3) summary ì—†ìŒ/ë¬´ì˜ë¯¸ -> ë³¸ë¬¸ í™•ì¸
        if (not summary) or _is_meaningless_summary(summary):
            html = _fetch_html(link)
            if not html:
                a.summary = ""
                continue

            body_text, img_count = _extract_text_and_imgcount(html)

            # 3-1) ì´ë¯¸ì§€ë§Œ ê´‘ê³  -> ë¹ˆê°’
            if _is_image_only_ad_page(body_text, img_count):
                a.summary = ""
                continue

            # 3-2) ë³¸ë¬¸ í…ìŠ¤íŠ¸ -> AI ìš”ì•½(ê°€ëŠ¥í•˜ë©´)
            if client is not None:
                try:
                    prompt = _prompt_summarize_from_body(title, body_text, language)
                    summary = _call_openai(client, prompt, temperature=0.2)
                except Exception:
                    summary = _norm_text(body_text)
            else:
                summary = _norm_text(body_text)

            summary = _enforce_sentence_and_length(summary, max_sentences=3, max_chars=MAX_SUMMARY_CHARS)
            if _is_en(language) and MIN_SUMMARY_CHARS:
                summary = _ensure_min_chars_english(summary, title, MIN_SUMMARY_CHARS, MAX_SUMMARY_CHARS, client)

            a.summary = summary
            continue

        # 2) summary == title -> ì œëª© ì •ë³´ë§Œìœ¼ë¡œ 2~3ë¬¸ì¥(ì¶”ì¸¡ ì ˆëŒ€ ê¸ˆì§€)
        if _is_summary_same_as_title(title, summary):
            if client is not None:
                try:
                    prompt = _prompt_title_only(title, language)
                    summary = _call_openai(client, prompt, temperature=0.2)
                except Exception:
                    summary = title
            else:
                summary = title

            summary = _enforce_sentence_and_length(summary, max_sentences=3, max_chars=MAX_SUMMARY_CHARS)
            if _is_en(language) and MIN_SUMMARY_CHARS:
                summary = _ensure_min_chars_english(summary, title, MIN_SUMMARY_CHARS, MAX_SUMMARY_CHARS, client)

            a.summary = summary
            continue

        # 1) summaryê°€ ê¸¸ë©´ -> ì••ì¶• ìš”ì•½
        if len(summary) >= LONG_SUMMARY_THRESHOLD:
            if client is not None:
                try:
                    prompt = _prompt_compress_long_summary(title, summary, language)
                    summary = _call_openai(client, prompt, temperature=0.2)
                except Exception:
                    pass

        # âœ… ë„¤ì´ë²„ëŠ” ê¸¸ì´ì™€ ìƒê´€ì—†ì´ í•œë²ˆ ë” AI ì •ë¦¬(ê¸°ì¡´ ì •ì±… ìœ ì§€)
        if is_naver and client is not None:
            try:
                prompt = _prompt_compress_long_summary(title, summary, language)
                summary = _call_openai(client, prompt, temperature=0.2)
            except Exception:
                pass

        summary = _enforce_sentence_and_length(summary, max_sentences=3, max_chars=MAX_SUMMARY_CHARS)
        if _is_en(language) and MIN_SUMMARY_CHARS:
            summary = _ensure_min_chars_english(summary, title, MIN_SUMMARY_CHARS, MAX_SUMMARY_CHARS, client)

        a.summary = summary


# =========================
# B. ìƒë‹¨ ì „ì²´ ìš”ì•½
# =========================
def summarize_overall(articles: List, language: str = "ko") -> str:
    """
    âœ… ì„ì›ìš© "ì–´ì œ ê¸°ì‚¬ AI ë¸Œë¦¬í•‘"
    - ì…ë ¥(ì œëª©/ìš”ì•½) ë²”ìœ„ ë‚´ì—ì„œë§Œ ì´ìŠˆ ë‹¨ìœ„ë¡œ ë¬¶ì–´ ìš”ì•½
    - ì˜ì–´ ëª¨ë“œì—ì„œ ë„ˆë¬´ ì§§ê²Œ ì˜ë ¤ ë¹ˆì•½í•´ì§€ëŠ” ë¬¸ì œë¥¼ ì¤„ì´ê¸° ìœ„í•´ char limitë§Œ í˜„ì‹¤ì ìœ¼ë¡œ ì¡°ì •
    """
    if not articles:
        if _is_en(language):
            return "There were no relevant articles collected for yesterday, so there is nothing additional to brief."
        return "ì–´ì œ ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì§‘ëœ ê´€ë ¨ ê¸°ì‚¬ê°€ ì—†ì–´ ë³„ë„ ê³µìœ  ì‚¬í•­ì€ ì—†ìŠµë‹ˆë‹¤."

    client = _get_client()
    if client is None:
        return _fallback_overall(language=language)

    items = []
    for a in articles[:10]:
        t = (getattr(a, "title", "") or "").strip()
        s = (getattr(a, "summary", "") or "").strip()
        s = re.sub(r"\s+", " ", s).strip()

        if not s:
            continue

        if _is_en(language):
            items.append(f"- Title: {t}\n  Summary: {s}")
        else:
            items.append(f"- ì œëª©: {t}\n  ìš”ì•½: {s}")

    if not items:
        if _is_en(language):
            return "Yesterdayâ€™s collected items did not contain usable text summaries, so there is nothing to consolidate."
        return "ì–´ì œëŠ” ìˆ˜ì§‘ëœ ê¸°ì‚¬ ì¤‘ í…ìŠ¤íŠ¸ ìš”ì•½ì´ ê°€ëŠ¥í•œ í•­ëª©ì´ ì—†ì–´, ì£¼ìš” ì´ìŠˆë¥¼ ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."

    target_sentences = _auto_sentence_target(len(items))

    if _is_en(language):
        max_chars = 650
        min_chars = 220
        prompt = f"""
You are an executive assistant writing a daily briefing for executives in the contact lens / optical industry.
Write a "Yesterday AI Briefing" using ONLY the input [Titles/Summaries] below.

ABSOLUTE RULES (MOST IMPORTANT):
- Use ONLY the facts stated in the input. Do NOT add any new facts, numbers, entities, brands, causes, or outcomes.
- No exaggeration, no speculation, no forecasting, no interpretation.
- Keep proper nouns as-is (Korean names/brands are allowed as proper nouns).
- Output MUST be in English.

OUTPUT FORMAT (IMPORTANT):
- Exactly {target_sentences} sentences.
- Sentence 1: One-sentence overall wrap-up (yesterdayâ€™s main flow within the input).
- Sentences 2â€“{target_sentences}: Summarize by distinct issues (group similar items into ONE sentence per issue).
- Do NOT list one sentence per article.
- Aim for at least {min_chars} characters but not more than {max_chars} characters.

[Titles/Summaries]
{chr(10).join(items)}
""".strip()
    else:
        max_chars = 420
        prompt = f"""
ë„ˆëŠ” ì½˜íƒíŠ¸ë Œì¦ˆ/ì•ˆê²½ ì—…ê³„ ë°ì¼ë¦¬ ë‰´ìŠ¤ë ˆí„°ë¥¼ ì„ì›ì—ê²Œ ë³´ê³ í•˜ëŠ” ë¹„ì„œë‹¤.
ì•„ë˜ [ê¸°ì‚¬ ì œëª©/ìš”ì•½]ë§Œì„ ê·¼ê±°ë¡œ 'ì–´ì œ ê¸°ì‚¬ AI ë¸Œë¦¬í•‘'ì„ ì‘ì„±í•˜ë¼.

ğŸš« ì ˆëŒ€ ê·œì¹™ (ê°€ì¥ ì¤‘ìš”):
- ì•„ë˜ ì…ë ¥ì— ì—†ëŠ” ì‚¬ì‹¤/ìˆ«ì/ì£¼ì²´/ë¸Œëœë“œ/ì›ì¸/ê²°ê³¼ë¥¼ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ ê²ƒ
- ê³¼ì¥/ì¶”ì¸¡/ì „ë§/í‰ê°€ ê¸ˆì§€
- ìœ ì‚¬í•œ ê¸°ì‚¬/ë™ì¼ ì‚¬ê±´ì€ í•˜ë‚˜ì˜ ì´ìŠˆë¡œ ë¬¶ì–´ì„œ 1ë¬¸ì¥ìœ¼ë¡œë§Œ ì‘ì„±

âœ… ì¶œë ¥ í˜•ì‹(ì¤‘ìš”):
- ì´ {target_sentences}ë¬¸ì¥ (ë¬¸ì¥ ìˆ˜ ì •í™•íˆ ì§€í‚¬ ê²ƒ)
- 1ë¬¸ì¥ì§¸: ì „ì²´ ì´í‰(ì–´ì œ í•µì‹¬ íë¦„/ê²½í–¥ì„ 1ë¬¸ì¥ìœ¼ë¡œ)
- 2~{target_sentences}ë¬¸ì¥ì§¸: ì„œë¡œ ë‹¤ë¥¸ 'ì´ìŠˆ' ë‹¨ìœ„ë¡œ ìš”ì•½
- ì „ì²´ {max_chars}ì ì´ë‚´

[ê¸°ì‚¬ ì œëª©/ìš”ì•½]
{chr(10).join(items)}
""".strip()

    try:
        text = _call_openai(client, prompt, temperature=0.2)
        text = _enforce_sentence_and_length(text, max_sentences=3, max_chars=max_chars)

        # ì˜ì–´ ëª¨ë“œì—ì„œ ë„ˆë¬´ ì§§ê²Œ ë‚˜ì™”ìœ¼ë©´ ê°™ì€ ì˜ë¯¸ë¡œ ë³´ê°• (íŒ©íŠ¸ ì¶”ê°€ ì—†ì´)
        if _is_en(language) and len(_norm_text(text)) < 220:
            text = _ensure_min_chars_english(text, title="Yesterday AI Briefing", min_chars=220, max_chars=max_chars, client=client)

        return text
    except Exception:
        return _fallback_overall(language=language)
